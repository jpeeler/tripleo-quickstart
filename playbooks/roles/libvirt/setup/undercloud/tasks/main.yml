- name: install libguestfs-tools
  yum: name=libguestfs-tools state=present
  become: true

- name: get MACs for the undercloud
  generate_macs:
    nodes: "{{ vms.undercloud.nodes }}"
    bridges: "{{ networks.bridges }}"
  register: undercloud_mac_map

- name: get expected md5 of undercloud appliance
  command: >
    curl -sf "{{url}}.md5"
  register: undercloud_md5

- name: get undercloud appliance
  register: get_undercloud_result
  until: get_undercloud_result.msg.find('did not match') == -1
  retries: 3
  delay: 10
  get_url:
    url: '{{ url }}'
    dest: '{{ working_dir }}'
    timeout: 1200
    checksum: 'md5:{{ undercloud_md5.stdout.split()[0] }}'
  become: true
  become_user: "{{non_root_user}}"

- name: copy instackenv.json to appliance
  shell: |
    export LIBGUESTFS_BACKEND=direct
    virt-customize -a {{ working_dir }}/undercloud.qcow2 \
      --run-command 'rm -f /home/stack/instackenv.json'
    virt-customize --upload {{ working_dir }}/instackenv.json:/home/stack/instackenv.json \
      -a {{ working_dir }}/undercloud.qcow2
  become: true
  become_user: "{{non_root_user}}"

- name: inject ssh key to appliance
  shell: |
    virt-customize --mkdir {{item.homedir}}/.ssh/ \
      -a {{ working_dir }}/undercloud.qcow2
    cp /home/{{ non_root_user }}/.ssh/id_rsa.pub \
      {{ working_dir }}/authorized_keys
    chmod 600 {{ working_dir }}/authorized_keys
    virt-customize --upload \
      {{ working_dir }}/authorized_keys:{{item.homedir}}/.ssh/authorized_keys \
      -a {{ working_dir }}/undercloud.qcow2
    virt-customize --run-command 'sudo chown {{item.owner}}:{{item.group}} \
      {{item.homedir}}/.ssh/authorized_keys' \
      -a {{ working_dir }}/undercloud.qcow2
  with_items:
    - homedir: /root
      owner: root
      group: root
    - homedir: /home/stack
      owner: stack
      group: stack
  environment:
    LIBGUESTFS_BACKEND: direct
  become: true
  become_user: "{{non_root_user}}"

- name: Install undercloud vm storage
  shell: |
    export LIBGUESTFS_BACKEND=direct
    virsh pool-refresh {{ vms.volume_pool}}
    virsh vol-create-as {{ vms.volume_pool}} {{ item.name }}.qcow2 \
      {{ item.disk_size }}G --format qcow2
    virt-resize --expand /dev/sda1 {{ working_dir }}/undercloud.qcow2 \
      '{{ vms.volume_path }}''{{ item.name }}'.qcow2
  with_items: "{{ vms.undercloud.nodes }}"
  async: 300
  poll: 10
  register: undercloud_copy
  ignore_errors: true
  become: true

- name: Output debug message if undercloud copy hangs
  fail:
    msg: >
      Undercloud copy took more than 5 minutes, it is likely that there is not enough
      space in {{ vms.volume_path }}
  when: undercloud_copy.failed is defined

- name: define undercloud vm
  virt:
    name: "{{ item.name }}"
    command: define
    xml: "{{ lookup('template', 'undercloudvm.xml.j2') }}"
  with_items: "{{ vms.undercloud.nodes }}"
  become: true

- name: start undercloud vm
  virt:
    name: "{{ item.name }}"
    command: start
  with_items: "{{ vms.undercloud.nodes }}"
  become: true

- name: get undercloud vm ip address
  script: "scripts/get-undercloud-ip.sh {{ vms.undercloud.nodes[0].name }}"
  register: undercloud_vm_ip_result
  until: undercloud_vm_ip_result.stdout != ''
  retries: 12
  delay: 10
  become: true

- name: set_fact for undercloud ip
  set_fact: "undercloud_ip={{ undercloud_vm_ip_result.stdout }}"

- name: wait until ssh is available on undercloud node
  wait_for:
    host: "{{ undercloud_ip }}"
    state: started
    port: 22
    delay: 15
    timeout: 300

- name: add undercloud host(s)
  add_host:
    name: "{{ item.name }}"
    groups: undercloud
    ansible_host: "{{ item.name }}"
    ansible_fqdn: "{{ item.name }}"
    ansible_user: stack
    ansible_private_key_file: "{{local_working_dir}}/id_rsa_virt_host"
    ansible_ssh_extra_args: '-F "{{local_working_dir}}/ssh.config.ansible"'
  with_items: "{{ vms.undercloud.nodes }}"

- name: setup ssh config
  template:
    src: ssh.config.j2
    dest: "{{ working_dir }}/ssh.config.ansible"
    mode: 0755
  become: true
  become_user: "{{non_root_user}}"

- name: copy ssh_config back to the local host
  fetch:
    src: "{{ working_dir }}/ssh.config.ansible"
    dest: "{{ local_working_dir }}/ssh.config.ansible"
    flat: yes
  become: true
  become_user: "{{non_root_user}}"

- name: copy ssh private key back to the local host
  fetch:
    src: "/home/{{ non_root_user }}/.ssh/id_rsa"
    dest: "{{ local_working_dir }}/id_rsa_virt_host"
    flat: yes
  become: true
  become_user: "{{non_root_user}}"

- name: set permissions on private key file
  delegate_to: localhost
  file:
    path: "{{ local_working_dir }}/id_rsa_virt_host"
    mode: "0600"
